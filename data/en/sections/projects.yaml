# section information
section:
  name: Projects
  id: projects
  enable: true
  weight: 5
  showOnNavbar: true
  # Can optionally hide the title in sections
  # hideTitle: true

# filter buttons
buttons:
- name: All
  filter: "all"
- name: Professional
  filter: "professional"
# - name: Academic
#   filter: "academic"
- name: Hobby
  filter: "hobby"

# your projects
projects:
- name: Junia Jungle Trekking website
  logo: /images/sections/projects/kubernetes.png
  role: Developer
  timeline: "Mar 2023 - Present"
  # repo: https://github.com/kubernetes/kubernetes # If your project is a public repo on GitHub, then provide this link. it will show star count.
  #url: ""  # If your project is not a public repo but it has a website or any external details url then provide it here. don't provide "repo" and "url" simultaneously.
  summary: Website built using Hugo for guest house offering jungle trekking in Gunung Leuser National Park, North Sumatra.
  tags: ["professional", "web-design", "hugo"]

- name: Fantasy Football Analytics
  logo: /images/sections/projects/tensorflow.png
  role: Owner
  timeline: "Apr 2023 - Present"
  repo: https://github.com/matthh9797/fantasy-football-recommender
  #url: ""
  summary: End-to-end data analytics project for analysing data from the Premier League Fantasy Football API. 
  tags: ["hobby", "gcp", "dbt", "cloud-run"]

- name: PalmBloo
  logo: /images/sections/projects/no-code.png
  role: Owner
  timeline: "Nov 2022 - Present"
  repo: https://github.com/matthh9797/palmbloo
  #url: ""
  summary: Travel blogging website advertised on social media.
  tags: ["hobby", "web-design", "hugo"]

- name: Loyalty reporting pipeline
  logo: /images/sections/projects/toha.png
  role: Owner
  timeline: "Jun 2019 - Present"
  # repo: https://github.com/hossainemruz/toha
  summary: >
    Analytics engineering business reporting pipeline built for large telecommunications company. Written using best-practice data modelling, robust testing, 
    and comprehensive documentation. Features include incremental models to handle big data, seperate environments for dev/prod, testing legitemacy of manually
    entered data as pre-hook and BQML analysis running at the end of the pipeline.
  tags: ["professional", "gcp", "dbt", "python"]
